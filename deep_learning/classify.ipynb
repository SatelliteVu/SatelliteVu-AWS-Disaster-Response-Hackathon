{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4d92ca5-9068-4a4f-a5da-2bb12fc57771",
   "metadata": {},
   "source": [
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/SatelliteVu/SatelliteVu-AWS-Disaster-Response-Hackathon/blob/main/deep_learning/classify.ipynb)\n",
    "\n",
    "In this notebook, we load a trained model and use it to make predicitions on samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6057dc-c584-4c02-a661-7ccd50382fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import keras\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "from config import common_config, dataset_config, training_config, model_config, test_config, classification_config\n",
    "import model_resunet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a59bae3-57fd-436b-a2ac-7c2fdc7a9560",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "input_dir = os.path.join(common_config[\"INPUT_DIR\"],\"classification_input\")\n",
    "\n",
    "output_predictions_dir = os.path.join(common_config[\"OUTPUT_DIR\"], \"predictions\")\n",
    "if not os.path.exists(output_predictions_dir):\n",
    "    os.makedirs(output_predictions_dir)\n",
    "\n",
    "model_dir = os.path.join(common_config[\"OUTPUT_DIR\"], \"model\")\n",
    "\n",
    "model_pattern = model_dir + \"/*{}*.h5\".format(test_config[\"wandb_model_nickname\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66449fd-7be5-4c3d-be22-44d4c114677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for a model\n",
    "model_paths = glob.glob(model_pattern)\n",
    "if not len(model_paths) == 1:\n",
    "    print(\"One model must be provided.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Define ResUNet model\n",
    "model = model_resunet.get_model([model_config[\"IMG_SIZE\"][0],model_config[\"IMG_SIZE\"][1],len(dataset_config[\"INPUT_FEATURES\"])])\n",
    "\n",
    "# Load model weights\n",
    "model.load_weights(os.path.join(model_paths[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341c6569-fa73-4098-bf40-d670b054327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input .npy files and get them ready for classification. Also read target output for visualisation.\n",
    "input_data = []\n",
    "targets = []\n",
    "\n",
    "for sample_id in classification_config[\"SAMPLE_IDS\"]:\n",
    "    sample_dir = os.path.join(input_dir, str(sample_id))\n",
    "    input_filenames = list()\n",
    "    for input_feature_name in dataset_config[\"INPUT_FEATURES\"]:\n",
    "        found_fname = glob.glob(sample_dir+'/{}*.npy'.format(input_feature_name))  \n",
    "        input_filenames.append(found_fname[0])\n",
    "    combined_data = np.array([np.load(fname) for fname in input_filenames])\n",
    "    input_data.append(combined_data)\n",
    "    \n",
    "    output_filenames = list()\n",
    "    for target_feature_name in dataset_config[\"OUTPUT_FEATURES\"]:\n",
    "        found_fname = glob.glob(sample_dir+'/{}*.npy'.format(target_feature_name))  \n",
    "        output_filenames.append(found_fname[0])\n",
    "    target_array = np.array([np.load(fname) for fname in output_filenames])\n",
    "    targets.append(target_array)\n",
    "\n",
    "input_data = np.moveaxis(np.array(input_data), 1, -1)\n",
    "targets = np.moveaxis(np.array(targets), 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8504f679-1af6-464f-a660-7b5fb4f250d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip and rescale values according to dataset stats.\n",
    "for i, input_feature_name in enumerate(dataset_config[\"INPUT_FEATURES\"]):\n",
    "    min_val, max_val, _, _ = dataset_config[\"DATA_STATS\"][input_feature_name]\n",
    "    input_data[:, :, :, i] = np.clip(input_data[:, :, :, i], min_val, max_val)\n",
    "    \n",
    "    if not input_feature_name in dataset_config[\"FEATURES_NOT_NORM\"]:\n",
    "        input_data[:, :, :, i] = np.divide((input_data[:, :, :, i]-min_val), (max_val - min_val), out=np.zeros_like(input_data[:, :, :, i]), where=(max_val - min_val)!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1743976-b2cd-47c6-ab44-b225f742281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "preds = list()\n",
    "for input_sample in input_data:\n",
    "    input_sample = np.expand_dims(input_sample, axis=0)\n",
    "    pred = model.predict(input_sample)\n",
    "    preds.append(pred)\n",
    "preds = np.array(preds).squeeze(axis=1)\n",
    "masks = np.round(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca7268a-c92c-41b8-bdcf-656d637f4350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions (classification and probabilities) as .npy files.\n",
    "for sample_id, mask, pred in zip(classification_config[\"SAMPLE_IDS\"], masks, preds):\n",
    "    classif_output_dir = os.path.join(output_predictions_dir, str(sample_id))\n",
    "    if not os.path.exists(classif_output_dir):\n",
    "        os.makedirs(classif_output_dir)\n",
    "    classification_filepath = os.path.join(classif_output_dir, \"classification\")\n",
    "    probabilities_filepath = os.path.join(classif_output_dir, \"probabilities\")\n",
    "    np.save(classification_filepath, mask)\n",
    "    np.save(probabilities_filepath, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54450267-c66a-4d44-9724-3b14f0171e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outputs, target output, previous day fire mask.\n",
    "CMAP = colors.ListedColormap(['silver', 'orangered'])\n",
    "BOUNDS = [0., 1.]\n",
    "NORM = colors.BoundaryNorm(BOUNDS, CMAP.N)\n",
    "\n",
    "img_ind = 0\n",
    "\n",
    "plt.imshow(input_data[img_ind, :, :, -1], cmap=CMAP, norm=NORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3590618f-ff9a-4f57-b705-c5e30fcb256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(targets[img_ind, :, :, 0], cmap=CMAP, norm=NORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a081bd-d24d-4004-a202-6763c049b778",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(masks[img_ind, :, :], cmap=CMAP, norm=NORM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2d9279-b743-412e-8180-00e1bde37600",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(preds[img_ind, :, :], cmap='Reds') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382d35bb-f7c2-4ccd-9c1b-d9c3712e32fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_titles = [\"Input previous day fire mask\", \"Ground truth next day fire mask\", \"Predicted next day fire mask\" ]\n",
    "\n",
    "n_rows = 1\n",
    "n_features = len(output_titles)\n",
    "\n",
    "CMAP = colors.ListedColormap(['silver', 'orangered'])\n",
    "BOUNDS = [0., 1.]\n",
    "NORM = colors.BoundaryNorm(BOUNDS, CMAP.N)\n",
    "\n",
    "fig = plt.figure(figsize=(30,13))\n",
    "\n",
    "for i in range(n_rows):\n",
    "    for j in range(n_features):\n",
    "        plt.subplot(n_rows, n_features + 1, i * (n_features + 1) + j + 1)\n",
    "        if i == 0:\n",
    "            plt.title(output_titles[j], fontsize=20)\n",
    "        if j == 0:\n",
    "            plt.imshow(input_data[i, :, :, -1], cmap=CMAP, norm=NORM) \n",
    "        if j == 1:\n",
    "            plt.imshow(targets[i, :, :, 0], cmap=CMAP, norm=NORM)\n",
    "        if j == 2:\n",
    "            plt.imshow(masks[i, :, :, 0], cmap=CMAP, norm=NORM) \n",
    "        plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow:Python",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
